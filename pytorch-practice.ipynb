{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.192356Z",
     "iopub.status.idle": "2021-12-21T11:54:08.192907Z",
     "shell.execute_reply": "2021-12-21T11:54:08.192691Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.192668Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.193974Z",
     "iopub.status.idle": "2021-12-21T11:54:08.194531Z",
     "shell.execute_reply": "2021-12-21T11:54:08.194328Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.194287Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "!nvidia-smi  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.195582Z",
     "iopub.status.idle": "2021-12-21T11:54:08.196142Z",
     "shell.execute_reply": "2021-12-21T11:54:08.195923Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.195901Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader             # Dataset用于存放数据集，DataLoader为数据迭代器\n",
    "from torch import nn                                         # 模型模块"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 构造tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.197186Z",
     "iopub.status.idle": "2021-12-21T11:54:08.197745Z",
     "shell.execute_reply": "2021-12-21T11:54:08.197531Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.197509Z"
    }
   },
   "outputs": [],
   "source": [
    "data = [[1,2],[3,4]]\n",
    "x_list = torch.tensor(data)            # 通过list构造\n",
    "\n",
    "array = np.array(data)\n",
    "x_array = torch.tensor(array)          # 通过np.array构造\n",
    "\n",
    "x_ones = torch.ones_like(x_list)       # 通过tensor构造，构造一个维度相同的全1tensor\n",
    "x_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.198800Z",
     "iopub.status.idle": "2021-12-21T11:54:08.199370Z",
     "shell.execute_reply": "2021-12-21T11:54:08.199148Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.199126Z"
    }
   },
   "outputs": [],
   "source": [
    "shape = (2,3)\n",
    "# 构造2*3维的全1，全0，随机tensor\n",
    "torch.ones(shape)\n",
    "torch.rand(shape)\n",
    "torch.zeros(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 查看tensor属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.200252Z",
     "iopub.status.idle": "2021-12-21T11:54:08.201043Z",
     "shell.execute_reply": "2021-12-21T11:54:08.200804Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.200779Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.ones((2,3))\n",
    "# 查看tensor的形状、数据类型、存储设备（CPU or GPU）\n",
    "x.shape\n",
    "print(x.dtype)\n",
    "x.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark: 关于tensor类型 <https://zhuanlan.zhihu.com/p/64647295>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 tensor操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.202181Z",
     "iopub.status.idle": "2021-12-21T11:54:08.202937Z",
     "shell.execute_reply": "2021-12-21T11:54:08.202713Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.202689Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.ones((2,3))\n",
    "if torch.cuda.is_available():                                  # 将tensor存储到gpu上\n",
    "    x = x.to('cuda')\n",
    "    print(f\"Device tensor is stored on: {x.device}\")\n",
    "# x = torch.rand(1, 28, 28, device=device)                     # 定义tensor时指定device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.204041Z",
     "iopub.status.idle": "2021-12-21T11:54:08.204796Z",
     "shell.execute_reply": "2021-12-21T11:54:08.204578Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.204555Z"
    }
   },
   "outputs": [],
   "source": [
    "x[:,0] = 2                        # 按索引赋值\n",
    "print(x)\n",
    "t = torch.cat([x, x], dim=1)      # 合并tensor\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.205885Z",
     "iopub.status.idle": "2021-12-21T11:54:08.206651Z",
     "shell.execute_reply": "2021-12-21T11:54:08.206426Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.206401Z"
    }
   },
   "outputs": [],
   "source": [
    "print(x*x)                    # *：对应位置相乘\n",
    "print(x.mul(x))               # x.mul()：对应位置相乘\n",
    "print(x.matmul(x.T))          # x.matmul()：矩阵乘法\n",
    "print(x @ x.T)                # @：矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.208890Z",
     "iopub.status.idle": "2021-12-21T11:54:08.209528Z",
     "shell.execute_reply": "2021-12-21T11:54:08.209317Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.209294Z"
    }
   },
   "outputs": [],
   "source": [
    "x.add_(5)               # 自加操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 tensor&numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.210688Z",
     "iopub.status.idle": "2021-12-21T11:54:08.211353Z",
     "shell.execute_reply": "2021-12-21T11:54:08.211136Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.211114Z"
    }
   },
   "outputs": [],
   "source": [
    "t = torch.tensor([1,2])\n",
    "a = t.numpy()                 # tensor->array\n",
    "t.add_(1)\n",
    "a                             # tensor的变化会影响array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.212566Z",
     "iopub.status.idle": "2021-12-21T11:54:08.213240Z",
     "shell.execute_reply": "2021-12-21T11:54:08.213029Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.213005Z"
    }
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2])\n",
    "t = torch.from_numpy(a)    # array->tensor\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset&DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 载入内置Dataset（Fashion MNIST）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.214468Z",
     "iopub.status.idle": "2021-12-21T11:54:08.215125Z",
     "shell.execute_reply": "2021-12-21T11:54:08.214890Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.214868Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",                      # 文件存储位置\n",
    "    train=True,                       # 表示训练集\n",
    "    download=True,                    # root路径下无数据则下载\n",
    "    transform=ToTensor()              # 将数据转换为tensor\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.216321Z",
     "iopub.status.idle": "2021-12-21T11:54:08.216973Z",
     "shell.execute_reply": "2021-12-21T11:54:08.216732Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.216710Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 自定义Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.218202Z",
     "iopub.status.idle": "2021-12-21T11:54:08.218847Z",
     "shell.execute_reply": "2021-12-21T11:54:08.218621Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.218598Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "\n",
    "class CustomImageDataset(Dataset):           # Dataset的子类\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):    # 初始化函数\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):                       # 数据集长度函数\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):              # 根据索引idx读取数据\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 创建DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.220065Z",
     "iopub.status.idle": "2021-12-21T11:54:08.220686Z",
     "shell.execute_reply": "2021-12-21T11:54:08.220474Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.220452Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)         # shuffle\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n",
    "\n",
    "train_features, train_labels = next(iter(train_dataloader))                       # dataloader是一个迭代器                  \n",
    "print(f\"Feature batch shape: {train_features.size()}\")\n",
    "print(f\"Labels batch shape: {train_labels.size()}\")\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap=\"gray\")\n",
    "plt.show()\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 数据变换"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 one-hot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.221917Z",
     "iopub.status.idle": "2021-12-21T11:54:08.222575Z",
     "shell.execute_reply": "2021-12-21T11:54:08.222361Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.222339Z"
    }
   },
   "outputs": [],
   "source": [
    "class_num = 10\n",
    "batch_size = 4\n",
    "label = torch.LongTensor(batch_size, 1).random_() % class_num\n",
    "# dim=1, index=label, src=torch.ones(batch_size, 1)，对原数组按照dim和index，从src中取元素进行修改\n",
    "torch.zeros(batch_size, class_num).scatter_(1, label, torch.ones(batch_size, 1))      # 这里的torch.ones(batch_size, 1)也可以写为1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Nerual Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 检查GPU是否可用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.223788Z",
     "iopub.status.idle": "2021-12-21T11:54:08.224432Z",
     "shell.execute_reply": "2021-12-21T11:54:08.224216Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.224194Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义模型类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.225613Z",
     "iopub.status.idle": "2021-12-21T11:54:08.226273Z",
     "shell.execute_reply": "2021-12-21T11:54:08.226059Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.226036Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):                     # 是nn.Module的一个子类\n",
    "    def __init__(self):                             # 初始化模型\n",
    "        super(NeuralNetwork, self).__init__()       # 调用父类的初始化方法\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):                          # 对输入进行的操作\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.nn是pytorch的高阶API，类似于tensorflow中的keras**  \n",
    "In PyTorch, the nn package serves this same purpose. The nn package defines a set of Modules, which are roughly equivalent to neural network layers. A Module receives input Tensors and computes output Tensors, but may also hold internal state such as Tensors containing learnable parameters. The nn package also defines a set of useful loss functions that are commonly used when training neural networks.  \n",
    "Read More: <https://pytorch.org/tutorials/beginner/nn_tutorial.html#neural-net-from-scratch-no-torch-nn>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.227490Z",
     "iopub.status.idle": "2021-12-21T11:54:08.228135Z",
     "shell.execute_reply": "2021-12-21T11:54:08.227905Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.227883Z"
    }
   },
   "outputs": [],
   "source": [
    "model = NeuralNetwork().to(device)                # 将模型放到指定的device上\n",
    "print(model)                                      # 打印模型结构\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")            # 查看模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.229325Z",
     "iopub.status.idle": "2021-12-21T11:54:08.230024Z",
     "shell.execute_reply": "2021-12-21T11:54:08.229780Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.229758Z"
    }
   },
   "outputs": [],
   "source": [
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(f\"Predicted class: {y_pred}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 常用的layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.231321Z",
     "iopub.status.idle": "2021-12-21T11:54:08.231966Z",
     "shell.execute_reply": "2021-12-21T11:54:08.231726Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.231704Z"
    }
   },
   "outputs": [],
   "source": [
    "nn.Flatten()\n",
    "nn.Linear(in_features = 10, out_features = 1)\n",
    "nn.ReLU()\n",
    "softmax = nn.Softmax(dim=1)\n",
    "print(softmax(logits))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更多用法见<https://pytorch.org/docs/stable/nn.html>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 一个简单案例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.233194Z",
     "iopub.status.idle": "2021-12-21T11:54:08.233839Z",
     "shell.execute_reply": "2021-12-21T11:54:08.233618Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.233595Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)            # requires_grad表示可以计算梯度\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)\n",
    "\n",
    "loss.backward()                                     # 计算loss关于参数的梯度\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-08T09:04:31.769193Z",
     "iopub.status.busy": "2021-11-08T09:04:31.768929Z",
     "iopub.status.idle": "2021-11-08T09:04:31.774164Z",
     "shell.execute_reply": "2021-11-08T09:04:31.773328Z",
     "shell.execute_reply.started": "2021-11-08T09:04:31.769165Z"
    }
   },
   "source": [
    "A function that we apply to tensors to construct computational graph is in fact an object of class Function.   \n",
    "This object knows how to compute the function in the forward direction, and also how to compute its derivative during the backward propagation step.   \n",
    "A reference to the backward propagation function is stored in grad_fn property of a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only obtain the grad properties for the leaf nodes of the computational graph, which have requires_grad property set to True. For all other nodes in our graph, gradients will not be available.  \n",
    "We can only perform gradient calculations using backward once on a given graph, for performance reasons. If we need to do several backward calls on the same graph, we need to pass retain_graph=True to the backward call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.235022Z",
     "iopub.status.idle": "2021-12-21T11:54:08.235651Z",
     "shell.execute_reply": "2021-12-21T11:54:08.235438Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.235415Z"
    }
   },
   "outputs": [],
   "source": [
    "# 禁止计算梯度\n",
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "\n",
    "z = torch.matmul(x, w)+b\n",
    "z_det = z.detach()              # 返回一个从当前图中分离的变量，其不需要梯度\n",
    "print(z_det.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint: 关于requires_grad, requires_grad_(), detach(), torch.no_grad()**  \n",
    "- requires_grad: 生成tensor时的参数\n",
    "- requires_grad_(): tensor类的函数，使用时对tensor进行in_place更新\n",
    "- detach(): tensor类的函数，使用时返回一个新的tensor对象，其requires_grad参数为False，**是原tensor的赋值引用**，共用同一内存\n",
    "- torch.no_grad(): with torch.no_grad()，后的操作都不计算梯度，常用于模型推断以加快计算速度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.236846Z",
     "iopub.status.idle": "2021-12-21T11:54:08.237502Z",
     "shell.execute_reply": "2021-12-21T11:54:08.237289Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.237266Z"
    }
   },
   "outputs": [],
   "source": [
    "x1 = torch.Tensor([1,2,3])\n",
    "x2 = torch.tensor([1.0, 2.0], requires_grad=True)            # 注意这里不能用Tensor函数初始化\n",
    "x1.requires_grad_()\n",
    "y = x2.detach()\n",
    "x1.requires_grad, x2.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 自定义函数的反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.238711Z",
     "iopub.status.idle": "2021-12-21T11:54:08.239373Z",
     "shell.execute_reply": "2021-12-21T11:54:08.239156Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.239133Z"
    }
   },
   "outputs": [],
   "source": [
    "class GradCoeff(torch.autograd.Function):       \n",
    "       \n",
    "    @staticmethod\n",
    "    def forward(ctx, x, coeff):                 # 模型前向\n",
    "        ctx.coeff = coeff                       # 将coeff存为ctx的成员变量\n",
    "        #return x.view_as(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):             # 模型梯度反传\n",
    "        return ctx.coeff * grad_output, None    # backward的输出个数，应与forward的输入个数相同，此处coeff不需要梯度，因此返回None\n",
    "\n",
    "# 尝试使用\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "ret = GradCoeff.apply(x, -0.1)                  # 前向需要同时提供x及coeff，设置coeff为-0.1\n",
    "ret = ret ** 3                          \n",
    "print(ret)                                      # tensor([4.], grad_fn=<PowBackward0>)\n",
    "ret.backward()  \n",
    "print(x.grad)                                   # tensor([-0.4000])，梯度已乘以相应系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.240549Z",
     "iopub.status.idle": "2021-12-21T11:54:08.241221Z",
     "shell.execute_reply": "2021-12-21T11:54:08.241003Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.240978Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomLayer, self).__init__()\n",
    "    def forward(self, input):\n",
    "        # See the autograd section for explanation of what happens here.\n",
    "        return GradCoeff.apply(input, -0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.242409Z",
     "iopub.status.idle": "2021-12-21T11:54:08.243057Z",
     "shell.execute_reply": "2021-12-21T11:54:08.242822Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.242789Z"
    }
   },
   "outputs": [],
   "source": [
    "layer = CustomLayer()\n",
    "x = layer(torch.tensor([1.], requires_grad=True))\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark: Finetune <https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.244236Z",
     "iopub.status.idle": "2021-12-21T11:54:08.244890Z",
     "shell.execute_reply": "2021-12-21T11:54:08.244661Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.244638Z"
    }
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark: Hyperparameter tuning <https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.246098Z",
     "iopub.status.idle": "2021-12-21T11:54:08.246712Z",
     "shell.execute_reply": "2021-12-21T11:54:08.246500Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.246478Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()        # 注意：使用crossentropyloss时不需要softmax层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.247900Z",
     "iopub.status.idle": "2021-12-21T11:54:08.248577Z",
     "shell.execute_reply": "2021-12-21T11:54:08.248365Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.248342Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "- Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.（每个batch要重置梯度）\n",
    "- Backpropagate the prediction loss with a call to loss.backwards(). PyTorch deposits the gradients of the loss w.r.t. each parameter.（反向传播梯度）\n",
    "- Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass.（更新参数）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mark: Optimizer <https://pytorch.org/docs/stable/optim.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train&Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.249798Z",
     "iopub.status.idle": "2021-12-21T11:54:08.250445Z",
     "shell.execute_reply": "2021-12-21T11:54:08.250231Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.250208Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):         # 表示一个epoch的训练过程\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):                # batch的最大值=len(dataset)/batch_size\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the key parts of training are: \n",
    "- A network is created.\n",
    "\n",
    "- An optimizer (in this case, a stochastic gradient descent optimizer) is created, and the network’s parameters are associated with it- .\n",
    "\n",
    "- A training loop…\n",
    " - acquires an input,\n",
    " - runs the network,\n",
    " - computes a loss,\n",
    " - zeros the network’s parameters’ gradients,\n",
    " - calls loss.backward() to update the parameters’ gradients,\n",
    " - calls optimizer.step() to apply the gradients to the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Full Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.251639Z",
     "iopub.status.idle": "2021-12-21T11:54:08.252306Z",
     "shell.execute_reply": "2021-12-21T11:54:08.252091Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.252069Z"
    }
   },
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "model.train()\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意训练模式和评估模式的切换**  \n",
    "Note that the above process is done entirely while the network module is in “training mode”.   \n",
    "Modules default to training mode and can be switched between training and evaluation modes using train() and eval(). They can behave differently depending on which mode they are in.   \n",
    "For example, **the BatchNorm module maintains a running mean and variance during training that are not updated when the module is in evaluation mode.**  \n",
    "In general, modules should be in training mode during training and only switched to evaluation mode for inference or evaluation.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.253486Z",
     "iopub.status.idle": "2021-12-21T11:54:08.254139Z",
     "shell.execute_reply": "2021-12-21T11:54:08.253906Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.253883Z"
    }
   },
   "outputs": [],
   "source": [
    "# 判断模型是否处于训练状态\n",
    "class ModalModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        if self.training:\n",
    "      # Add a constant only in training mode.\n",
    "            return x + 1.\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save&Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.255322Z",
     "iopub.status.idle": "2021-12-21T11:54:08.255995Z",
     "shell.execute_reply": "2021-12-21T11:54:08.255752Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.255729Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.vgg16(pretrained=True)\n",
    "torch.save(model.state_dict(), 'model_weights.pth')           # model.state_dict()得到的是一个存放模型参数的字典\n",
    "model = models.vgg16() # we do not specify pretrained=True, i.e. do not load default weights\n",
    "model.load_state_dict(torch.load('model_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 保存整个模型（参数+结构）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.257170Z",
     "iopub.status.idle": "2021-12-21T11:54:08.257790Z",
     "shell.execute_reply": "2021-12-21T11:54:08.257575Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.257552Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')\n",
    "model = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-09T12:37:45.07563Z",
     "iopub.status.busy": "2021-11-09T12:37:45.074539Z",
     "iopub.status.idle": "2021-11-09T12:37:45.082002Z",
     "shell.execute_reply": "2021-11-09T12:37:45.081198Z",
     "shell.execute_reply.started": "2021-11-09T12:37:45.075573Z"
    }
   },
   "source": [
    "### 3. 保存checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading a general checkpoint model for inference or resuming training can be helpful for picking up where you last left off.   \n",
    "When saving a general checkpoint, you must save more than just the model’s state_dict.   \n",
    "- It is important to also save the **optimizer’s state_dict**, as this contains buffers and parameters that are updated as the model trains.   \n",
    "- Other items that you may want to save are **the epoch you left off on, the latest recorded training loss, external torch.nn.Embedding layers**, and more, based on your own algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.259021Z",
     "iopub.status.idle": "2021-12-21T11:54:08.259665Z",
     "shell.execute_reply": "2021-12-21T11:54:08.259452Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.259429Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义并初始化模型\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(4),        # 对输入进行归一化\n",
    "            nn.Linear(4, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "    \n",
    "model = NeuralNetwork().double()\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "EPOCH = 5\n",
    "PATH = \"model.pt\"\n",
    "LOSS = 0.4\n",
    "\n",
    "# 存储checkpoint\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.260885Z",
     "iopub.status.idle": "2021-12-21T11:54:08.261524Z",
     "shell.execute_reply": "2021-12-21T11:54:08.261309Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.261287Z"
    }
   },
   "outputs": [],
   "source": [
    "# 读取checkpoint\n",
    "model = NeuralNetwork().double()\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A manual Logistic Regression (AS an example of custom nn.Module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load data, create dataset&dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.262710Z",
     "iopub.status.idle": "2021-12-21T11:54:08.263377Z",
     "shell.execute_reply": "2021-12-21T11:54:08.263160Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.263138Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息\n",
    "\n",
    "def minmax_scaler(data):\n",
    "    min_value = data.min(axis=0)\n",
    "    max_value = data.max(axis=0)\n",
    "    return (data-min_value)/(max_value-min_value)\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "x, y = torch.Tensor(minmax_scaler(cancer_data.data)).to(device), torch.Tensor(cancer_data.target).to(device) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.264577Z",
     "iopub.status.idle": "2021-12-21T11:54:08.265249Z",
     "shell.execute_reply": "2021-12-21T11:54:08.265032Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.265009Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x,y)   # 生成dataset对象\n",
    "\n",
    "# 随机划分训练集与测试集\n",
    "train_size, test_size = int(0.7*len(dataset)), len(dataset)-int(0.7*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.266433Z",
     "iopub.status.idle": "2021-12-21T11:54:08.267100Z",
     "shell.execute_reply": "2021-12-21T11:54:08.266867Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.266843Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class LR(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(in_features, 1))\n",
    "        self.bias = nn.Parameter(torch.randn(1))\n",
    "    def linear(self, inputs):\n",
    "        logits = inputs@self.weight+self.bias\n",
    "        return logits.to(device)\n",
    "    def sigmoid(self, logits):\n",
    "        return 1/(1+torch.exp(-logits))\n",
    "    def forward(self, inputs):\n",
    "        prob = self.sigmoid(self.linear(inputs))\n",
    "        prob = prob.squeeze(-1)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.268260Z",
     "iopub.status.idle": "2021-12-21T11:54:08.268920Z",
     "shell.execute_reply": "2021-12-21T11:54:08.268693Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.268671Z"
    }
   },
   "outputs": [],
   "source": [
    "# More complex model (with mlp feature extractor)\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(30, 10),\n",
    "    nn.ReLU(10),\n",
    "    nn.BatchNorm1d(10),\n",
    "    LR(10)\n",
    ")\n",
    "lr_model = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.270132Z",
     "iopub.status.idle": "2021-12-21T11:54:08.270777Z",
     "shell.execute_reply": "2021-12-21T11:54:08.270563Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.270540Z"
    }
   },
   "outputs": [],
   "source": [
    "# More complex model (with mlp feature extractor and custom module)\n",
    "class net(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.fe = nn.Sequential(\n",
    "            nn.Linear(in_features, 20),\n",
    "            nn.ReLU(20),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.BatchNorm1d(20),\n",
    "        )\n",
    "        self.lr = LR(20)\n",
    "    def forward(self, inputs):\n",
    "        x = self.fe(inputs)\n",
    "        prob = self.lr(x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Initialize Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.273824Z",
     "iopub.status.idle": "2021-12-21T11:54:08.274465Z",
     "shell.execute_reply": "2021-12-21T11:54:08.274252Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.274229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model parameter\n",
    "# Note that no_grad() is used here to avoid tracking this computation in the autograd graph.\n",
    "@torch.no_grad()\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        m.bias.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Module hooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.275639Z",
     "iopub.status.idle": "2021-12-21T11:54:08.276305Z",
     "shell.execute_reply": "2021-12-21T11:54:08.276090Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.276068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Not finished"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define train&test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.277528Z",
     "iopub.status.idle": "2021-12-21T11:54:08.278197Z",
     "shell.execute_reply": "2021-12-21T11:54:08.277985Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.277947Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred)==y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.279382Z",
     "iopub.status.idle": "2021-12-21T11:54:08.280048Z",
     "shell.execute_reply": "2021-12-21T11:54:08.279801Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.279778Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)               # 设定随机种子以复现实验结果（相同seed下网络初始化相同）\n",
    "\n",
    "feature_size = len(train_dataset[0][0])\n",
    "lr_model = LR(feature_size).to(device)\n",
    "# lr_model.to(dtype=torch.float32)      # 改变模型精度\n",
    "# lr_model = net(feature_size).to(device)\n",
    "\n",
    "# Apply the function recursively on the module and its submodules.\n",
    "# lr_model.apply(init_weights)\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()    # 经过sigmoid\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.Adam(lr_model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "\n",
    "lr_model.train()\n",
    "if lr_model.training:\n",
    "    print('Under training mode')\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, lr_model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, lr_model, loss_fn)\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.281243Z",
     "iopub.status.idle": "2021-12-21T11:54:08.281880Z",
     "shell.execute_reply": "2021-12-21T11:54:08.281657Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.281634Z"
    }
   },
   "outputs": [],
   "source": [
    "# 查看自定义module结构\n",
    "for child in lr_model.named_children():\n",
    "    print(child)\n",
    "# print(lr_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.283273Z",
     "iopub.status.idle": "2021-12-21T11:54:08.283948Z",
     "shell.execute_reply": "2021-12-21T11:54:08.283715Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.283691Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict result on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.285181Z",
     "iopub.status.idle": "2021-12-21T11:54:08.285800Z",
     "shell.execute_reply": "2021-12-21T11:54:08.285587Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.285565Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model.eval()\n",
    "with torch.no_grad():\n",
    "    prob = lr_model(test_dataset[:][0])\n",
    "    y_pred = (prob>0.5).type(torch.float)           \n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "t = lambda x1, x2: int(x1==x2)\n",
    "accuracy = sum(list(map(t, y_pred, test_dataset[:][1])))/len(list(map(t, y_pred, test_dataset[:][1])))\n",
    "print(f\"accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-10T08:58:50.348025Z",
     "iopub.status.busy": "2021-10-10T08:58:50.347633Z",
     "iopub.status.idle": "2021-10-10T08:58:50.392377Z",
     "shell.execute_reply": "2021-10-10T08:58:50.391254Z",
     "shell.execute_reply.started": "2021-10-10T08:58:50.347987Z"
    }
   },
   "source": [
    "## Example for classification（Iris dataset）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Get device for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.287026Z",
     "iopub.status.idle": "2021-12-21T11:54:08.287659Z",
     "shell.execute_reply": "2021-12-21T11:54:08.287445Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.287422Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.288896Z",
     "iopub.status.idle": "2021-12-21T11:54:08.289539Z",
     "shell.execute_reply": "2021-12-21T11:54:08.289323Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.289301Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "iris_data = load_iris()\n",
    "# 将Numpy数组转换为tensor，同时将数据转移至指定的device上\n",
    "x, y = torch.Tensor(iris_data.data).to(device), torch.tensor(iris_data.target).to(device)        \n",
    "dataset = TensorDataset(x,y)   # 生成dataset对象\n",
    "\n",
    "# 随机划分训练集与测试集\n",
    "train_size, test_size = int(0.7*len(dataset)), int(0.3*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：大写的torch.Tensor()得到的是float32类型的tensor，与nn的默认参数类型相同，否则会报错**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.290723Z",
     "iopub.status.idle": "2021-12-21T11:54:08.291393Z",
     "shell.execute_reply": "2021-12-21T11:54:08.291177Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.291155Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define the network (Use nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.292569Z",
     "iopub.status.idle": "2021-12-21T11:54:08.293235Z",
     "shell.execute_reply": "2021-12-21T11:54:08.293024Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.293001Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\"\"\"\n",
    "net是一个Sequential类的实例，其为串联在一起的多个层定义了一个容器\n",
    "nn.Linear表示全连接层\n",
    "\"\"\"\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(4, 3)       # 标签共三类，使用Crossentropyloss，不需要softmax层\n",
    ")\n",
    "# net = net.double()\n",
    "model = net.to(device)    # 将模型放在指定的device上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Define the network (Use subclass of nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.294423Z",
     "iopub.status.idle": "2021-12-21T11:54:08.295091Z",
     "shell.execute_reply": "2021-12-21T11:54:08.294857Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.294834Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(4),        # 对输入进行归一化\n",
    "            nn.Linear(4, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "    \n",
    "#model = NeuralNetwork().double()\n",
    "model = NeuralNetwork()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Define the network (Combine model, loss, lr, optimizer in a model class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.296279Z",
     "iopub.status.idle": "2021-12-21T11:54:08.296911Z",
     "shell.execute_reply": "2021-12-21T11:54:08.296685Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.296663Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNN, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(4),        # 对输入进行归一化\n",
    "            nn.Linear(4, 3)\n",
    "        )\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.lr = 1e-2\n",
    "        self.optimizer = torch.optim.SGD(self.parameters(), lr=self.lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        return logits\n",
    "    \n",
    "#model = MyNN().double()\n",
    "model = MyNN()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the train loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Using pure model (without loss&optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.298143Z",
     "iopub.status.idle": "2021-12-21T11:54:08.298780Z",
     "shell.execute_reply": "2021-12-21T11:54:08.298566Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.298543Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Using customed model (with loss&optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.300009Z",
     "iopub.status.idle": "2021-12-21T11:54:08.300637Z",
     "shell.execute_reply": "2021-12-21T11:54:08.300423Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.300400Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)\n",
    "        loss = model.loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        model.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        \n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += model.loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += model.loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the defined network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Train with pure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.301838Z",
     "iopub.status.idle": "2021-12-21T11:54:08.302496Z",
     "shell.execute_reply": "2021-12-21T11:54:08.302282Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.302259Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "model.train()\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Train with customed model(with loss&optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.303678Z",
     "iopub.status.idle": "2021-12-21T11:54:08.304321Z",
     "shell.execute_reply": "2021-12-21T11:54:08.304105Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.304083Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, model)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model)\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.305512Z",
     "iopub.status.idle": "2021-12-21T11:54:08.306177Z",
     "shell.execute_reply": "2021-12-21T11:54:08.305966Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.305928Z"
    }
   },
   "outputs": [],
   "source": [
    "# 画训练曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Get the predict value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.307351Z",
     "iopub.status.idle": "2021-12-21T11:54:08.308002Z",
     "shell.execute_reply": "2021-12-21T11:54:08.307757Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.307735Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits = model(test_dataset[:][0])\n",
    "    pred_probab = nn.Softmax(dim=1)(logits)\n",
    "    y_pred = pred_probab.argmax(1)             # argmax(1)返回数组各个横轴上最大值的索引\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "t = lambda x1, x2: int(x1==x2)\n",
    "accuracy = sum(list(map(t, y_pred, test_dataset[:][1])))/len(list(map(t, y_pred, test_dataset[:][1])))\n",
    "print(f\"accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for regression (California Housing dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.309194Z",
     "iopub.status.idle": "2021-12-21T11:54:08.309841Z",
     "shell.execute_reply": "2021-12-21T11:54:08.309615Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.309593Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.311057Z",
     "iopub.status.idle": "2021-12-21T11:54:08.311676Z",
     "shell.execute_reply": "2021-12-21T11:54:08.311462Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.311440Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "X,y = fetch_california_housing(return_X_y=True)\n",
    "print(f\"The shape of input is: {len(X[0])}\")\n",
    "# 将Numpy数组转换为tensor，同时将数据转移至指定的device上 \n",
    "dataset = TensorDataset(torch.Tensor(X).to(device),torch.Tensor(y).to(device))   # 生成dataset对象\n",
    "\n",
    "# 随机划分训练集与测试集\n",
    "train_size, test_size = int(0.7*len(dataset)), len(dataset)-int(0.7*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-10-14T11:43:15.716256Z",
     "iopub.status.busy": "2021-10-14T11:43:15.715459Z",
     "iopub.status.idle": "2021-10-14T11:43:15.723062Z",
     "shell.execute_reply": "2021-10-14T11:43:15.722131Z",
     "shell.execute_reply.started": "2021-10-14T11:43:15.716205Z"
    }
   },
   "source": [
    "### Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.312884Z",
     "iopub.status.idle": "2021-12-21T11:54:08.313541Z",
     "shell.execute_reply": "2021-12-21T11:54:08.313327Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.313305Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Define the network (Use nn.Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.314728Z",
     "iopub.status.idle": "2021-12-21T11:54:08.315380Z",
     "shell.execute_reply": "2021-12-21T11:54:08.315164Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.315142Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\"\"\"\n",
    "net是一个Sequential类的实例，其为串联在一起的多个层定义了一个容器\n",
    "nn.Linear表示全连接层\n",
    "\"\"\"\n",
    "net = nn.Sequential(\n",
    "    nn.BatchNorm1d(8),\n",
    "    nn.Linear(8, 16),       \n",
    "    nn.ReLU(16),\n",
    "    nn.BatchNorm1d(16),\n",
    "    nn.Linear(16,1)\n",
    ")\n",
    "# net = net.double()        # 网络参数类型为double型（与输入相同）\n",
    "model = net.to(device)    # 将模型放在指定的device上"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Define the network (Use subclass of nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.316598Z",
     "iopub.status.idle": "2021-12-21T11:54:08.317263Z",
     "shell.execute_reply": "2021-12-21T11:54:08.317050Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.317027Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu = nn.Sequential(\n",
    "            nn.BatchNorm1d(8),        # 对输入进行归一化\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(16),           \n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16,1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_relu(x)\n",
    "        logits = logits.squeeze(-1)\n",
    "        return logits\n",
    "    \n",
    "#model = NeuralNetwork().double()\n",
    "model = NeuralNetwork()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.318483Z",
     "iopub.status.idle": "2021-12-21T11:54:08.319134Z",
     "shell.execute_reply": "2021-12-21T11:54:08.318903Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.318881Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)                    # why need reshape?\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)                    # 当前batch的train_loss\n",
    "            print(f\"Train loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test MSE Error: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.320325Z",
     "iopub.status.idle": "2021-12-21T11:54:08.320980Z",
     "shell.execute_reply": "2021-12-21T11:54:08.320739Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.320716Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define model hyperparameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "model.train()\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"Test MSE Error: {epoch_test_loss:.3f} \\n\")\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.322178Z",
     "iopub.status.idle": "2021-12-21T11:54:08.322808Z",
     "shell.execute_reply": "2021-12-21T11:54:08.322593Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.322571Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "model.eval()\n",
    "y_pred = model(test_dataset[:][0]).cpu().detach().numpy()\n",
    "y_test = test_dataset[:][1].cpu().detach().numpy()\n",
    "print(f\"R2 score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test):.3f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.set(ylabel='AI', xlabel='样本点')\n",
    "ax.scatter(y_test, y_pred, s=2, color='mediumblue',alpha=0.2)\n",
    "x = np.linspace(0, 5, 5)\n",
    "ax.plot(x,x,'k')\n",
    "plt.xlabel('true', fontsize=15)\n",
    "plt.ylabel('predict', fontsize=15)\n",
    "#plt.legend(['True','Predict'], fontsize=15)\n",
    "plt.grid(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.324041Z",
     "iopub.status.idle": "2021-12-21T11:54:08.324662Z",
     "shell.execute_reply": "2021-12-21T11:54:08.324452Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.324430Z"
    }
   },
   "outputs": [],
   "source": [
    "# 画训练曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.325837Z",
     "iopub.status.idle": "2021-12-21T11:54:08.326490Z",
     "shell.execute_reply": "2021-12-21T11:54:08.326272Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.326249Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.327685Z",
     "iopub.status.idle": "2021-12-21T11:54:08.328357Z",
     "shell.execute_reply": "2021-12-21T11:54:08.328130Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.328107Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.329548Z",
     "iopub.status.idle": "2021-12-21T11:54:08.330194Z",
     "shell.execute_reply": "2021-12-21T11:54:08.329978Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.329942Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "data_1 = pd.DataFrame()\n",
    "file_path = '../input/nh3-dann/'\n",
    "value_name = ['FI3024', 'PDI3012', 'PIC3030', 'TI3037',\n",
    "              'TI3038', 'TI4043', 'PI4043', 'FIC3004', \n",
    "              'FI4040', 'PI4040', 'TI4040', 'TI4042', 'PI4042', 'AI3012']\n",
    "for name in value_name:\n",
    "    data_1[name] = pd.read_csv(file_path+name+'.csv').value\n",
    "data_1.dropna(inplace=True)\n",
    "data_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.331516Z",
     "iopub.status.idle": "2021-12-21T11:54:08.332164Z",
     "shell.execute_reply": "2021-12-21T11:54:08.331932Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.331910Z"
    }
   },
   "outputs": [],
   "source": [
    "Data_1 = pd.read_csv('../input/nh3dann2/10-02-11-02_1.csv')\n",
    "Data_2 = pd.read_csv('../input/nh3dann2/10-02-11-02_2.csv')\n",
    "Data_3 = pd.read_csv('../input/nh3dann2/10-02-11-02_3.csv')\n",
    "\n",
    "Data_AI12 = Data_2[Data_2.tag=='URE2.AI3012.PV'].value\n",
    "Data_AI12.index = np.arange(0,len(Data_AI12))\n",
    "Data_FI3024 = Data_3[Data_3.tag=='URE2.FI3024.PV'].value\n",
    "Data_FI3024.index = np.arange(0,len(Data_FI3024))\n",
    "Data_PDI3012 = Data_3[Data_3.tag=='URE2.PDI3012.PV'].value\n",
    "Data_PDI3012.index = np.arange(0,len(Data_PDI3012))\n",
    "Data_PIC3030 = Data_2[Data_2.tag=='URE2.PIC3030.PV'].value\n",
    "Data_PIC3030.index = np.arange(0,len(Data_PIC3030))\n",
    "Data_TI3037 = Data_3[Data_3.tag=='URE2.TI3037.PV'].value\n",
    "Data_TI3037.index = np.arange(0,len(Data_TI3037))\n",
    "Data_TI3038 = Data_2[Data_2.tag=='URE2.TI3038.PV'].value\n",
    "Data_TI3038.index = np.arange(0,len(Data_TI3038))\n",
    "Data_TI4043 = Data_3[Data_3.tag=='URE2.TI4043.PV'].value\n",
    "Data_TI4043.index = np.arange(0,len(Data_TI4043))\n",
    "Data_PI4043 = Data_3[Data_3.tag=='URE2.PI4043.PV'].value\n",
    "Data_PI4043.index = np.arange(0,len(Data_PI4043))\n",
    "Data_FIC3004 = Data_3[Data_3.tag=='URE2.FIC3004.PV'].value\n",
    "Data_FIC3004.index = np.arange(0,len(Data_FIC3004))\n",
    "Data_FI4040 = Data_3[Data_3.tag=='URE2.FI4040.PV'].value\n",
    "Data_FI4040.index = np.arange(0,len(Data_FI4040))\n",
    "Data_PI4040 = Data_3[Data_3.tag=='URE2.PI4040.PV'].value\n",
    "Data_PI4040.index = np.arange(0,len(Data_PI4040))\n",
    "Data_TI4040 = Data_3[Data_3.tag=='URE2.TI4040.PV'].value\n",
    "Data_TI4040.index = np.arange(0,len(Data_TI4040))\n",
    "Data_TI4042 = Data_3[Data_3.tag=='URE2.TI4042.PV'].value\n",
    "Data_TI4042.index = np.arange(0,len(Data_TI4042))\n",
    "Data_PI4042 = Data_3[Data_3.tag=='URE2.PI4042.PV'].value\n",
    "Data_PI4042.index = np.arange(0,len(Data_PI4042))\n",
    "\n",
    "Data_10 = pd.DataFrame({'FI3024':Data_FI3024, 'PDI3012':Data_PDI3012,\n",
    "                         'PIC3030':Data_PIC3030, 'TI3037':Data_TI3037,\n",
    "                         'TI3038':Data_TI3038, 'TI4043':Data_TI4043,\n",
    "                         'PI4043':Data_PI4043, 'FIC3004':Data_FIC3004,\n",
    "                         'FI4040':Data_FI4040, 'PI4040':Data_PI4040,\n",
    "                         'TI4040':Data_TI4040, 'TI4042':Data_TI4042,\n",
    "                         'PI4042':Data_PI4042, 'AI3012':Data_AI12})\n",
    "data_2 = Data_10.dropna()\n",
    "data_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.333344Z",
     "iopub.status.idle": "2021-12-21T11:54:08.334005Z",
     "shell.execute_reply": "2021-12-21T11:54:08.333766Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.333744Z"
    }
   },
   "outputs": [],
   "source": [
    "def MinMax(df):\n",
    "    s_df = pd.DataFrame(columns=df.columns)\n",
    "    for col in df.columns:\n",
    "        s_value = minmax_scale(df[col])\n",
    "        s_value = s_value.flatten()\n",
    "        s_df[col] = s_value\n",
    "    return s_df\n",
    "# 去除3sigma以外的异常值\n",
    "def RemoveOutlier(df):\n",
    "    for col in df.columns:\n",
    "        df = df[abs(df[col]-df[col].mean())<=3*df[col].std()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.335193Z",
     "iopub.status.idle": "2021-12-21T11:54:08.335833Z",
     "shell.execute_reply": "2021-12-21T11:54:08.335607Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.335584Z"
    }
   },
   "outputs": [],
   "source": [
    "data_1 = RemoveOutlier(data_1)\n",
    "data_2 = RemoveOutlier(data_2)\n",
    "data_source = data_1.iloc[130000:150000, :]\n",
    "data_target = data_2.iloc[20000:38500, :]       # target:20000-35000, test:35000-38500\n",
    "\n",
    "data_train = MinMax(data_source)\n",
    "data_test = MinMax(data_target)\n",
    "\n",
    "X_train = data_train.iloc[:, :13].values\n",
    "y_train = data_train.iloc[:, 13].values\n",
    "X_test = data_test.iloc[15000:, :13].values\n",
    "y_test = data_test.iloc[15000:, 13].values\n",
    "\n",
    "min_y, max_y = min(y_test), max(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slide Window Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.337032Z",
     "iopub.status.idle": "2021-12-21T11:54:08.337672Z",
     "shell.execute_reply": "2021-12-21T11:54:08.337459Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.337436Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_window(X, y, window_len):\n",
    "    data_len = len(X)\n",
    "    feature_len = len(X[0])\n",
    "    result = []\n",
    "    for index in range(data_len-window_len+1):\n",
    "        result.append(X[index: index+window_len])\n",
    "    result = np.array(result)\n",
    "    X_window = np.reshape(result, (result.shape[0], result.shape[1], feature_len))\n",
    "    y_window = y[window_len-1:]\n",
    "    return X_window, y_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.338881Z",
     "iopub.status.idle": "2021-12-21T11:54:08.339525Z",
     "shell.execute_reply": "2021-12-21T11:54:08.339311Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.339289Z"
    }
   },
   "outputs": [],
   "source": [
    "window_len = 3\n",
    "X_lstm_train, y_lstm_train = create_window(X_train, y_train, window_len)\n",
    "X_lstm_test, y_lstm_test = create_window(X_test, y_test, window_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-19T08:51:33.800825Z",
     "iopub.status.busy": "2021-11-19T08:51:33.800547Z",
     "iopub.status.idle": "2021-11-19T08:51:33.808704Z",
     "shell.execute_reply": "2021-11-19T08:51:33.807578Z",
     "shell.execute_reply.started": "2021-11-19T08:51:33.800797Z"
    }
   },
   "source": [
    "### Create dataset&dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.340730Z",
     "iopub.status.idle": "2021-12-21T11:54:08.341413Z",
     "shell.execute_reply": "2021-12-21T11:54:08.341198Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.341175Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "train_dataset = TensorDataset(torch.Tensor(X_lstm_train).to(device),torch.Tensor(y_lstm_train).to(device)) \n",
    "test_dataset = TensorDataset(torch.Tensor(X_lstm_test).to(device),torch.Tensor(y_lstm_test).to(device)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.342622Z",
     "iopub.status.idle": "2021-12-21T11:54:08.343277Z",
     "shell.execute_reply": "2021-12-21T11:54:08.343060Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.343037Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 128\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.344449Z",
     "iopub.status.idle": "2021-12-21T11:54:08.345114Z",
     "shell.execute_reply": "2021-12-21T11:54:08.344884Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.344861Z"
    }
   },
   "outputs": [],
   "source": [
    "rnn = nn.LSTM(13, 128, 1, batch_first=True)          # (feature_size, hidden_size, num_layers)\n",
    "inputs = torch.randn(128, 3, 13)    # (sequence length, batch_size, feature_size)/(batch_size, sequence length, feature_size) with batch_first=True\n",
    "output, _  = rnn(inputs)              # (sequence length, batch_size, output_size), (hidden_state, cell_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.346293Z",
     "iopub.status.idle": "2021-12-21T11:54:08.346921Z",
     "shell.execute_reply": "2021-12-21T11:54:08.346693Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.346671Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class lstm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(lstm, self).__init__()\n",
    "        self.fe = nn.Sequential(\n",
    "            nn.LSTM(13, 128, 1, batch_first=True)\n",
    "        )\n",
    "        self.predictor = nn.Sequential(\n",
    "            nn.Dropout(p=0.25),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feature, _ = self.fe(x)\n",
    "        pred = self.predictor(feature[:,-1])\n",
    "        pred = pred.squeeze(-1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.348196Z",
     "iopub.status.idle": "2021-12-21T11:54:08.348868Z",
     "shell.execute_reply": "2021-12-21T11:54:08.348644Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.348621Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)                    \n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)                    # 当前batch的train_loss\n",
    "            print(f\"Train loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test MSE Error: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.350081Z",
     "iopub.status.idle": "2021-12-21T11:54:08.350720Z",
     "shell.execute_reply": "2021-12-21T11:54:08.350506Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.350483Z"
    }
   },
   "outputs": [],
   "source": [
    "model = lstm().to(device)\n",
    "# Define model hyperparameters\n",
    "learning_rate = 3e-4\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "model.train()\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"Test MSE Error: {epoch_test_loss:.3f} \\n\")\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.351940Z",
     "iopub.status.idle": "2021-12-21T11:54:08.352585Z",
     "shell.execute_reply": "2021-12-21T11:54:08.352370Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.352348Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "model.eval()\n",
    "y_pred = model(test_dataset[:][0]).cpu().detach().numpy()\n",
    "y_test = test_dataset[:][1].cpu().detach().numpy()\n",
    "print(f\"R2 score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test):.3f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(10,5), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set(ylabel='AI', xlabel='样本点')\n",
    "ax.plot(y_test, marker='.', color='mediumblue')\n",
    "ax.plot(y_pred, marker='.', color='red')\n",
    "plt.xlabel('true', fontsize=15)\n",
    "plt.ylabel('predict', fontsize=15)\n",
    "#plt.legend(['True','Predict'], fontsize=15)\n",
    "plt.grid(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.353756Z",
     "iopub.status.idle": "2021-12-21T11:54:08.354617Z",
     "shell.execute_reply": "2021-12-21T11:54:08.354325Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.354244Z"
    }
   },
   "outputs": [],
   "source": [
    "# 画训练曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.355799Z",
     "iopub.status.idle": "2021-12-21T11:54:08.356552Z",
     "shell.execute_reply": "2021-12-21T11:54:08.356339Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.356316Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.357745Z",
     "iopub.status.idle": "2021-12-21T11:54:08.358407Z",
     "shell.execute_reply": "2021-12-21T11:54:08.358192Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.358169Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from torch import nn\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "def minmax_scaler(data):\n",
    "    min_value = data.min(axis=0)\n",
    "    max_value = data.max(axis=0)\n",
    "    return (data-min_value)/(max_value-min_value)\n",
    "\n",
    "cancer_data = load_breast_cancer()\n",
    "x, y = torch.Tensor(minmax_scaler(cancer_data.data)).to(device), torch.Tensor(cancer_data.target).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.359624Z",
     "iopub.status.idle": "2021-12-21T11:54:08.360285Z",
     "shell.execute_reply": "2021-12-21T11:54:08.360069Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.360046Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x,y)   # 生成dataset对象\n",
    "\n",
    "# 随机划分训练集与测试集\n",
    "train_size, test_size = int(0.7*len(dataset)), len(dataset)-int(0.7*len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.361489Z",
     "iopub.status.idle": "2021-12-21T11:54:08.362164Z",
     "shell.execute_reply": "2021-12-21T11:54:08.361911Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.361889Z"
    }
   },
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(in_features, 16),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(16, in_features),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "    def forward(self, inputs):\n",
    "        encoding = self.encoder(inputs)\n",
    "        rec = self.decoder(encoding)\n",
    "        return encoding, rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define train&test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.363378Z",
     "iopub.status.idle": "2021-12-21T11:54:08.364042Z",
     "shell.execute_reply": "2021-12-21T11:54:08.363802Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.363780Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        encoding, rec = model(X)\n",
    "        loss = loss_fn(rec, X)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(rec, X).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            encoding, rec = model(X)\n",
    "            test_loss += loss_fn(rec, X).item()\n",
    "            \n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    print(f\"Test Error: \\n Avg loss: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.365286Z",
     "iopub.status.idle": "2021-12-21T11:54:08.365914Z",
     "shell.execute_reply": "2021-12-21T11:54:08.365687Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.365664Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)               # 设定随机种子以复现实验结果（相同seed下网络初始化相同）\n",
    "\n",
    "feature_size = len(train_dataset[0][0])\n",
    "model = autoencoder(feature_size).to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "\n",
    "model.train()\n",
    "if model.training:\n",
    "    print('Under training mode')\n",
    "epochs = 20\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.367101Z",
     "iopub.status.idle": "2021-12-21T11:54:08.367773Z",
     "shell.execute_reply": "2021-12-21T11:54:08.367558Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.367535Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the encodings to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.369020Z",
     "iopub.status.idle": "2021-12-21T11:54:08.369657Z",
     "shell.execute_reply": "2021-12-21T11:54:08.369447Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.369426Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "train_encodings,_ = model(train_dataset[:][0])\n",
    "train_encodings = train_encodings.detach()\n",
    "test_encodings,_ = model(test_dataset[:][0])\n",
    "test_encodings = test_encodings.detach()\n",
    "\n",
    "train_dataset = TensorDataset(train_encodings,train_dataset[:][1])   # 生成dataset对象\n",
    "test_dataset = TensorDataset(test_encodings, test_dataset[:][1]) \n",
    "\n",
    "# 随机划分训练集与测试集\n",
    "batch_size = 16\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.370882Z",
     "iopub.status.idle": "2021-12-21T11:54:08.371529Z",
     "shell.execute_reply": "2021-12-21T11:54:08.371315Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.371293Z"
    }
   },
   "outputs": [],
   "source": [
    "class lr(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super(lr, self).__init__()\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.BatchNorm1d(in_features),        # 对输入进行归一化\n",
    "            nn.Linear(in_features, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear(x)\n",
    "        logits = logits.squeeze(-1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.372788Z",
     "iopub.status.idle": "2021-12-21T11:54:08.373432Z",
     "shell.execute_reply": "2021-12-21T11:54:08.373218Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.373196Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    train_loss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # 计算预测值与损失\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch % 5 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:.3f}  [{current:>5d}/{size:>5d}]\")\n",
    "        train_loss += loss_fn(pred, y).item()\n",
    "    return train_loss / num_batches                # 返回一个epoch内的平均训练损失\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (torch.round(pred)==y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:.3f} \\n\")\n",
    "    return test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.374622Z",
     "iopub.status.idle": "2021-12-21T11:54:08.375290Z",
     "shell.execute_reply": "2021-12-21T11:54:08.375077Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.375054Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)               # 设定随机种子以复现实验结果（相同seed下网络初始化相同）\n",
    "\n",
    "feature_size = len(train_dataset[0][0])\n",
    "lr_model = lr(feature_size).to(device)\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.BCELoss()\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(lr_model.parameters(), lr=learning_rate)\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "\n",
    "lr_model.train()\n",
    "if lr_model.training:\n",
    "    print('Under training mode')\n",
    "epochs = 30\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(train_dataloader, lr_model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, lr_model, loss_fn)\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.376502Z",
     "iopub.status.idle": "2021-12-21T11:54:08.377161Z",
     "shell.execute_reply": "2021-12-21T11:54:08.376933Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.376910Z"
    }
   },
   "outputs": [],
   "source": [
    "# 画训练曲线\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.378367Z",
     "iopub.status.idle": "2021-12-21T11:54:08.379029Z",
     "shell.execute_reply": "2021-12-21T11:54:08.378789Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.378766Z"
    }
   },
   "outputs": [],
   "source": [
    "lr_model.eval()\n",
    "with torch.no_grad():\n",
    "    prob = lr_model(test_dataset[:][0])\n",
    "    y_pred = (prob>0.5).type(torch.float)           # argmax(1)返回数组各个横轴上最大值的索引\n",
    "print(f\"Predicted class: {y_pred}\")\n",
    "\n",
    "t = lambda x1, x2: int(x1==x2)\n",
    "accuracy = sum(list(map(t, y_pred, test_dataset[:][1])))/len(list(map(t, y_pred, test_dataset[:][1])))\n",
    "print(f\"accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.380224Z",
     "iopub.status.idle": "2021-12-21T11:54:08.380887Z",
     "shell.execute_reply": "2021-12-21T11:54:08.380629Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.380607Z"
    }
   },
   "outputs": [],
   "source": [
    "model = torch.load('model.pth')\n",
    "print(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 将指定层设为参数更新，其余层参数不更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.383339Z",
     "iopub.status.idle": "2021-12-21T11:54:08.383991Z",
     "shell.execute_reply": "2021-12-21T11:54:08.383747Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.383725Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.linear_relu[4].parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.385180Z",
     "iopub.status.idle": "2021-12-21T11:54:08.385841Z",
     "shell.execute_reply": "2021-12-21T11:54:08.385618Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.385596Z"
    }
   },
   "outputs": [],
   "source": [
    "# 检查各层参数\n",
    "for child in model.children():\n",
    "    print(child)\n",
    "    for param in model.parameters():\n",
    "        print(param.requires_grad)\n",
    "        # print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 将优化器设置为只更新需要更新的部分参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.387024Z",
     "iopub.status.idle": "2021-12-21T11:54:08.387662Z",
     "shell.execute_reply": "2021-12-21T11:54:08.387448Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.387426Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 重新训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.388933Z",
     "iopub.status.idle": "2021-12-21T11:54:08.389574Z",
     "shell.execute_reply": "2021-12-21T11:54:08.389359Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.389336Z"
    }
   },
   "outputs": [],
   "source": [
    "# 增量训练集\n",
    "new_x, new_y = np.array([]), np.array([])\n",
    "for x, y in train_dataset:\n",
    "    if 4 < y < 5:\n",
    "        new_x = np.append(new_x, x.cpu().numpy())\n",
    "        new_y = np.append(new_y, y.cpu().numpy())\n",
    "new_x = new_x.reshape(-1,8)\n",
    "new_train_dataset = TensorDataset(torch.Tensor(new_x).to(device),torch.Tensor(new_y).to(device))\n",
    "\n",
    "batch_size = 64\n",
    "new_train_dataloader = DataLoader(new_train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.390792Z",
     "iopub.status.idle": "2021-12-21T11:54:08.391449Z",
     "shell.execute_reply": "2021-12-21T11:54:08.391235Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.391213Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "train_loss, test_loss = np.array([]), np.array([])\n",
    "\n",
    "model.train()\n",
    "epochs = 10\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    epoch_train_loss = train_loop(new_train_dataloader, model, loss_fn, optimizer)\n",
    "    epoch_test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"Test MSE Error: {epoch_test_loss:.3f} \\n\")\n",
    "    train_loss = np.append(train_loss, epoch_train_loss)\n",
    "    test_loss = np.append(test_loss, epoch_test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.392633Z",
     "iopub.status.idle": "2021-12-21T11:54:08.393319Z",
     "shell.execute_reply": "2021-12-21T11:54:08.393105Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.393083Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)\n",
    "plt.plot(np.linspace(1,epochs,epochs), test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.394519Z",
     "iopub.status.idle": "2021-12-21T11:54:08.395204Z",
     "shell.execute_reply": "2021-12-21T11:54:08.394988Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.394930Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.font_manager import FontProperties\n",
    "model.eval()\n",
    "y_pred = model(test_dataset[:][0]).cpu().detach().numpy()\n",
    "y_test = test_dataset[:][1].cpu().detach().numpy()\n",
    "print(f\"R2 score: {r2_score(y_test, y_pred):.3f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_pred, y_test):.3f}\")\n",
    "\n",
    "fig = plt.figure(figsize=(3,3), dpi=300)\n",
    "ax = fig.add_subplot(111)\n",
    "#ax.set(ylabel='AI', xlabel='样本点')\n",
    "ax.scatter(y_test, y_pred, s=2, color='mediumblue',alpha=0.2)\n",
    "x = np.linspace(0, 5, 5)\n",
    "ax.plot(x,x,'k')\n",
    "plt.xlabel('true', fontsize=15)\n",
    "plt.ylabel('predict', fontsize=15)\n",
    "#plt.legend(['True','Predict'], fontsize=15)\n",
    "plt.grid(True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Embedding（MF）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.396379Z",
     "iopub.status.idle": "2021-12-21T11:54:08.397023Z",
     "shell.execute_reply": "2021-12-21T11:54:08.396780Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.396758Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn \n",
    "from scipy.sparse import rand as sprand\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 生成测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.398210Z",
     "iopub.status.idle": "2021-12-21T11:54:08.398885Z",
     "shell.execute_reply": "2021-12-21T11:54:08.398660Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.398637Z"
    }
   },
   "outputs": [],
   "source": [
    "n_users = 100\n",
    "n_items = 100\n",
    "ratings = sprand(n_users, n_items, density=0.1, format=\"csr\")\n",
    "ratings.data = np.random.randint(1, 5, size=ratings.nnz).astype(np.float64)\n",
    "ratings = ratings.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.400097Z",
     "iopub.status.idle": "2021-12-21T11:54:08.400731Z",
     "shell.execute_reply": "2021-12-21T11:54:08.400516Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.400494Z"
    }
   },
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, n_users, n_items, embedding_dim=8):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_emb = nn.Embedding(n_users, embedding_dim, sparse=True)   # 把每个用户映射为一个embedding_dim维的稠密向量\n",
    "        self.item_emb = nn.Embedding(n_items, embedding_dim, sparse=True)   # 把每个物品映射为一个embedding_dim维的稠密向量\n",
    "\n",
    "    def forward(self, user, item):\n",
    "        user = torch.LongTensor([user]).to(device)\n",
    "        item = torch.LongTensor([item]).to(device)\n",
    "        return (self.user_emb(user) * self.item_emb(item)).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 设置模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.401978Z",
     "iopub.status.idle": "2021-12-21T11:54:08.402629Z",
     "shell.execute_reply": "2021-12-21T11:54:08.402413Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.402390Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(2)\n",
    "torch.cuda.manual_seed(2)               # 设定随机种子以复现实验结果（相同seed下网络初始化相同）\n",
    "\n",
    "mf_model = MF(n_users, n_items, embedding_dim=10).to(device)\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(mf_model.parameters(), lr=learning_rate)\n",
    "epochs = 10\n",
    "train_loss, test_loss = np.array([]), np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.403868Z",
     "iopub.status.idle": "2021-12-21T11:54:08.404512Z",
     "shell.execute_reply": "2021-12-21T11:54:08.404292Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.404270Z"
    }
   },
   "outputs": [],
   "source": [
    "rows, cols = ratings.nonzero()\n",
    "p = np.random.permutation(len(rows))\n",
    "rows, cols = rows[p], cols[p]\n",
    "\n",
    "mf_model.train()\n",
    "for t in range(epochs):\n",
    "    train_epoch_loss = 0\n",
    "    for row, col in zip(*(rows, cols)):\n",
    "        # Set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # Turn data into tensors\n",
    "        rating = torch.Tensor([ratings[row, col]]).to(device)\n",
    "        row = torch.LongTensor([row]).to(device)\n",
    "        col = torch.LongTensor([col]).to(device)\n",
    "\n",
    "        # Predict and calculate loss\n",
    "        prediction = mf_model(row, col)     # 参数类型为LongTensor\n",
    "        loss = loss_fn(prediction, rating)\n",
    "        train_epoch_loss += loss.item()\n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "        \n",
    "    train_loss = np.append(train_loss, train_epoch_loss/len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.405730Z",
     "iopub.status.idle": "2021-12-21T11:54:08.406390Z",
     "shell.execute_reply": "2021-12-21T11:54:08.406179Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.406155Z"
    }
   },
   "outputs": [],
   "source": [
    "len(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.407599Z",
     "iopub.status.idle": "2021-12-21T11:54:08.408262Z",
     "shell.execute_reply": "2021-12-21T11:54:08.408044Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.408021Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.linspace(1,epochs,epochs), train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2021-12-21T11:54:08.409449Z",
     "iopub.status.idle": "2021-12-21T11:54:08.410136Z",
     "shell.execute_reply": "2021-12-21T11:54:08.409908Z",
     "shell.execute_reply.started": "2021-12-21T11:54:08.409885Z"
    }
   },
   "outputs": [],
   "source": [
    "mf_model(0,13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for Factorization Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T12:38:53.170928Z",
     "iopub.status.busy": "2021-12-21T12:38:53.170650Z",
     "iopub.status.idle": "2021-12-21T12:38:58.213207Z",
     "shell.execute_reply": "2021-12-21T12:38:58.212442Z",
     "shell.execute_reply.started": "2021-12-21T12:38:53.170880Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn \n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))\n",
    "# !nvidia-smi      # 查看gpu信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-21T12:39:22.149652Z",
     "iopub.status.busy": "2021-12-21T12:39:22.148952Z",
     "iopub.status.idle": "2021-12-21T12:39:22.157165Z",
     "shell.execute_reply": "2021-12-21T12:39:22.156143Z",
     "shell.execute_reply.started": "2021-12-21T12:39:22.149614Z"
    }
   },
   "outputs": [],
   "source": [
    "class FM(nn.Module):\n",
    "    def __init__(self, feature_dim, embedding_dim=10):\n",
    "        super().__init__()\n",
    "        # Initially we fill V with random values sampled from Gaussian distribution\n",
    "        # NB: use nn.Parameter to compute gradients\n",
    "        self.V = nn.Parameter(torch.randn(feature_dim, embedding_dim), requires_grad=True)\n",
    "        self.linear = nn.Linear(feature_dim, 1)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out_1 = torch.matmul(x, self.V).pow(2).sum(1, keepdim=True) #S_1^2\n",
    "        out_2 = torch.matmul(x.pow(2), self.V.pow(2)).sum(1, keepdim=True) # S_2\n",
    "        \n",
    "        out_inter = 0.5*(out_1 - out_2)\n",
    "        out_linear = self.linear(x)\n",
    "        out = out_inter + out_linear\n",
    "        \n",
    "        return torch.sigmoid(out.squeeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- self-defined nn.module   \n",
    "<https://pytorch.org/docs/stable/notes/modules.html>\n",
    "- sequence model(RNN, LSTM, Transformer...)   \n",
    "<https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html?highlight=lstm#torch.nn.LSTM>   \n",
    "<https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html?highlight=transformer#torch.nn.Transformer>\n",
    "- Autoencoder  \n",
    "<https://github.com/L1aoXingyu/pytorch-beginner/blob/master/08-AutoEncoder/simple_autoencoder.py>\n",
    "- finetune  \n",
    "<https://anchorety.github.io/2019/11/07/pytorch%E2%80%94%E2%80%94finetune%E5%B8%B8%E7%94%A8%E4%BB%A3%E7%A0%81/>\n",
    "- pytorch lightning  \n",
    "<https://www.pytorchlightning.ai/tutorials>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
